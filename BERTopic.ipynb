{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "279128be-b12a-45ae-b1b0-4035dc03758d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "167a65b9-abcd-4c63-b82b-c0d8d55b246d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: boto3 in /home/studio-lab-user/.conda/envs/d2l/lib/python3.9/site-packages (1.34.115)\n",
      "Collecting sagemaker\n",
      "  Downloading sagemaker-2.221.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: botocore<1.35.0,>=1.34.115 in /home/studio-lab-user/.conda/envs/d2l/lib/python3.9/site-packages (from boto3) (1.34.115)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/studio-lab-user/.conda/envs/d2l/lib/python3.9/site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /home/studio-lab-user/.conda/envs/d2l/lib/python3.9/site-packages (from boto3) (0.10.1)\n",
      "Requirement already satisfied: attrs<24,>=23.1.0 in /home/studio-lab-user/.conda/envs/d2l/lib/python3.9/site-packages (from sagemaker) (23.2.0)\n",
      "Collecting cloudpickle==2.2.1 (from sagemaker)\n",
      "  Downloading cloudpickle-2.2.1-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: google-pasta in /home/studio-lab-user/.conda/envs/d2l/lib/python3.9/site-packages (from sagemaker) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.9.0 in /home/studio-lab-user/.conda/envs/d2l/lib/python3.9/site-packages (from sagemaker) (1.26.4)\n",
      "Requirement already satisfied: protobuf<5.0,>=3.12 in /home/studio-lab-user/.conda/envs/d2l/lib/python3.9/site-packages (from sagemaker) (4.25.3)\n",
      "Collecting smdebug-rulesconfig==1.0.1 (from sagemaker)\n",
      "  Downloading smdebug_rulesconfig-1.0.1-py2.py3-none-any.whl.metadata (943 bytes)\n",
      "Collecting importlib-metadata<7.0,>=1.4.0 (from sagemaker)\n",
      "  Downloading importlib_metadata-6.11.0-py3-none-any.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/studio-lab-user/.conda/envs/d2l/lib/python3.9/site-packages (from sagemaker) (24.0)\n",
      "Requirement already satisfied: pandas in /home/studio-lab-user/.conda/envs/d2l/lib/python3.9/site-packages (from sagemaker) (2.2.2)\n",
      "Collecting pathos (from sagemaker)\n",
      "  Downloading pathos-0.3.2-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting schema (from sagemaker)\n",
      "  Downloading schema-0.7.7-py2.py3-none-any.whl.metadata (34 kB)\n",
      "Requirement already satisfied: PyYAML~=6.0 in /home/studio-lab-user/.conda/envs/d2l/lib/python3.9/site-packages (from sagemaker) (6.0.1)\n",
      "Requirement already satisfied: jsonschema in /home/studio-lab-user/.conda/envs/d2l/lib/python3.9/site-packages (from sagemaker) (4.22.0)\n",
      "Requirement already satisfied: platformdirs in /home/studio-lab-user/.conda/envs/d2l/lib/python3.9/site-packages (from sagemaker) (4.2.2)\n",
      "Collecting tblib<4,>=1.7.0 (from sagemaker)\n",
      "  Downloading tblib-3.0.0-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: urllib3<3.0.0,>=1.26.8 in /home/studio-lab-user/.conda/envs/d2l/lib/python3.9/site-packages (from sagemaker) (1.26.18)\n",
      "Requirement already satisfied: requests in /home/studio-lab-user/.conda/envs/d2l/lib/python3.9/site-packages (from sagemaker) (2.32.2)\n",
      "Collecting docker (from sagemaker)\n",
      "  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: tqdm in /home/studio-lab-user/.conda/envs/d2l/lib/python3.9/site-packages (from sagemaker) (4.66.4)\n",
      "Requirement already satisfied: psutil in /home/studio-lab-user/.conda/envs/d2l/lib/python3.9/site-packages (from sagemaker) (5.9.8)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/studio-lab-user/.conda/envs/d2l/lib/python3.9/site-packages (from botocore<1.35.0,>=1.34.115->boto3) (2.9.0.post0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/studio-lab-user/.conda/envs/d2l/lib/python3.9/site-packages (from importlib-metadata<7.0,>=1.4.0->sagemaker) (3.18.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/studio-lab-user/.conda/envs/d2l/lib/python3.9/site-packages (from requests->sagemaker) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/studio-lab-user/.conda/envs/d2l/lib/python3.9/site-packages (from requests->sagemaker) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/studio-lab-user/.conda/envs/d2l/lib/python3.9/site-packages (from requests->sagemaker) (2024.2.2)\n",
      "Requirement already satisfied: six in /home/studio-lab-user/.conda/envs/d2l/lib/python3.9/site-packages (from google-pasta->sagemaker) (1.16.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/studio-lab-user/.conda/envs/d2l/lib/python3.9/site-packages (from jsonschema->sagemaker) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/studio-lab-user/.conda/envs/d2l/lib/python3.9/site-packages (from jsonschema->sagemaker) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/studio-lab-user/.conda/envs/d2l/lib/python3.9/site-packages (from jsonschema->sagemaker) (0.18.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/studio-lab-user/.conda/envs/d2l/lib/python3.9/site-packages (from pandas->sagemaker) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/studio-lab-user/.conda/envs/d2l/lib/python3.9/site-packages (from pandas->sagemaker) (2024.1)\n",
      "Collecting ppft>=1.7.6.8 (from pathos->sagemaker)\n",
      "  Downloading ppft-1.7.6.8-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting dill>=0.3.8 (from pathos->sagemaker)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting pox>=0.3.4 (from pathos->sagemaker)\n",
      "  Downloading pox-0.3.4-py3-none-any.whl.metadata (8.0 kB)\n",
      "Collecting multiprocess>=0.70.16 (from pathos->sagemaker)\n",
      "  Downloading multiprocess-0.70.16-py39-none-any.whl.metadata (7.2 kB)\n",
      "Downloading sagemaker-2.221.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading cloudpickle-2.2.1-py3-none-any.whl (25 kB)\n",
      "Downloading smdebug_rulesconfig-1.0.1-py2.py3-none-any.whl (20 kB)\n",
      "Downloading importlib_metadata-6.11.0-py3-none-any.whl (23 kB)\n",
      "Downloading tblib-3.0.0-py3-none-any.whl (12 kB)\n",
      "Downloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pathos-0.3.2-py3-none-any.whl (82 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading schema-0.7.7-py2.py3-none-any.whl (18 kB)\n",
      "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multiprocess-0.70.16-py39-none-any.whl (133 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.4/133.4 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pox-0.3.4-py3-none-any.whl (29 kB)\n",
      "Downloading ppft-1.7.6.8-py3-none-any.whl (56 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: schema, tblib, smdebug-rulesconfig, ppft, pox, importlib-metadata, dill, cloudpickle, multiprocess, docker, pathos, sagemaker\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib_metadata 7.1.0\n",
      "    Uninstalling importlib_metadata-7.1.0:\n",
      "      Successfully uninstalled importlib_metadata-7.1.0\n",
      "Successfully installed cloudpickle-2.2.1 dill-0.3.8 docker-7.1.0 importlib-metadata-6.11.0 multiprocess-0.70.16 pathos-0.3.2 pox-0.3.4 ppft-1.7.6.8 sagemaker-2.221.1 schema-0.7.7 smdebug-rulesconfig-1.0.1 tblib-3.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install boto3 sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32b5c959-f203-43b0-9228-000a74315b19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"kruthof/financial_phrasebank_fullTrainData\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"kruthof/financial_phrasebank_fullTrainData\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560f11ac-9a95-4dd8-aaa3-7dae3febfc6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc8e03c-195a-4cb9-9505-b4cdccb94f8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "603042d1-7c95-4173-b08e-803decd0b451",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at kruthof/financial_phrasebank_fullTrainData and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "model_name = 'kruthof/financial_phrasebank_fullTrainData'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5824be66-a443-4e3d-9dfb-5651f99a78ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def finbert_embeddings(texts):\n",
    "#     encoded_input = tokenizer(texts, padding=True, truncation=True, return_tensors='pt')\n",
    "#     with torch.no_grad():\n",
    "#         model_output = model(**encoded_input)\n",
    "    \n",
    "#     # Mean pooling to get sentence embeddings\n",
    "#     embeddings = model_output.last_hidden_state.mean(dim=1)\n",
    "#     return embeddings.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1db3f588-cabf-4faa-992d-228b5aaf2de5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from bertopic import BERTopic\n",
    "docs_old = pd.read_csv('combined_file.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "244f2646-4afd-475d-981f-282bb730cbb7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300010\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "print(len(docs_old))\n",
    "docs=docs_old['title'][1:100]\n",
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b34253d6-8f31-4803-9ef1-32303e75a057",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name kruthof/financial_phrasebank_fullTrainData. Creating a new one with mean pooling.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at kruthof/financial_phrasebank_fullTrainData and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.49 s, sys: 641 ms, total: 10.1 s\n",
      "Wall time: 5.72 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "topic_model = BERTopic(embedding_model=model_name)\n",
    "topics, probs = topic_model.fit_transform(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "486a8309-99fb-4943-a121-60a0a0439e36",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "      <th>Representation</th>\n",
       "      <th>Representative_Docs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>5</td>\n",
       "      <td>-1_week_stocks_corrupt_through</td>\n",
       "      <td>[week, stocks, corrupt, through, discussed, ch...</td>\n",
       "      <td>[JP Morgan now holds over $2.4 TRILLION in dep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>0_to_the_of_in</td>\n",
       "      <td>[to, the, of, in, stock, is, and, on, for, are]</td>\n",
       "      <td>[BREAKING: Fed Raises Interest Rates by 0.75 P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>1_of_market_on_the</td>\n",
       "      <td>[of, market, on, the, 2022, to, and, how, from...</td>\n",
       "      <td>[Most politicians can be good market timers an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>2_is_the_don_own</td>\n",
       "      <td>[is, the, don, own, hope, than, you, he, my, to]</td>\n",
       "      <td>[Does it annoy anyone else when people talk ab...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic  Count                            Name  \\\n",
       "0     -1      5  -1_week_stocks_corrupt_through   \n",
       "1      0     57                  0_to_the_of_in   \n",
       "2      1     27              1_of_market_on_the   \n",
       "3      2     10                2_is_the_don_own   \n",
       "\n",
       "                                      Representation  \\\n",
       "0  [week, stocks, corrupt, through, discussed, ch...   \n",
       "1    [to, the, of, in, stock, is, and, on, for, are]   \n",
       "2  [of, market, on, the, 2022, to, and, how, from...   \n",
       "3   [is, the, don, own, hope, than, you, he, my, to]   \n",
       "\n",
       "                                 Representative_Docs  \n",
       "0  [JP Morgan now holds over $2.4 TRILLION in dep...  \n",
       "1  [BREAKING: Fed Raises Interest Rates by 0.75 P...  \n",
       "2  [Most politicians can be good market timers an...  \n",
       "3  [Does it annoy anyone else when people talk ab...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a25d373e-f247-4b69-b42d-a0817504a543",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('of', 0.09654511915426452),\n",
       " ('market', 0.0655339606550848),\n",
       " ('on', 0.06408048463164191),\n",
       " ('the', 0.06146871805068928),\n",
       " ('2022', 0.05938945988203825),\n",
       " ('to', 0.05378512829435312),\n",
       " ('and', 0.0534004038597016),\n",
       " ('how', 0.047454563019416064),\n",
       " ('from', 0.04454209491152868),\n",
       " ('with', 0.042290324229472355)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model.get_topic(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1bc8358c-43d8-46b1-994d-db0cc4bab648",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Name</th>\n",
       "      <th>Representation</th>\n",
       "      <th>Representative_Docs</th>\n",
       "      <th>Top_n_words</th>\n",
       "      <th>Probability</th>\n",
       "      <th>Representative_document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Robinhood and other brokers literally blocking...</td>\n",
       "      <td>151</td>\n",
       "      <td>151_thread_broker_popular_hate</td>\n",
       "      <td>[thread, broker, popular, hate, experiencing, ...</td>\n",
       "      <td>[Robinhood says it’s experiencing a ‘system-wi...</td>\n",
       "      <td>thread - broker - popular - hate - experiencin...</td>\n",
       "      <td>0.746662</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>United Airlines stock down over 5% premarket t...</td>\n",
       "      <td>191</td>\n",
       "      <td>191_united_airlines_ual_planes</td>\n",
       "      <td>[united, airlines, ual, planes, events, dragge...</td>\n",
       "      <td>[A Month Ago, United Airlines Stock Dropped By...</td>\n",
       "      <td>united - airlines - ual - planes - events - dr...</td>\n",
       "      <td>0.965646</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bitcoin was nearly $20,000 a year ago today</td>\n",
       "      <td>287</td>\n",
       "      <td>287_cathy_crispr_invitae_square</td>\n",
       "      <td>[cathy, crispr, invitae, square, predicted, wo...</td>\n",
       "      <td>[Cathy Wood predicted Bitcoin, Tesla, Square, ...</td>\n",
       "      <td>cathy - crispr - invitae - square - predicted ...</td>\n",
       "      <td>0.904166</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If in 2001, you bought $399 of Apple stock ins...</td>\n",
       "      <td>179</td>\n",
       "      <td>179_62_399_blowout_authorizes</td>\n",
       "      <td>[62, 399, blowout, authorizes, ipod, original,...</td>\n",
       "      <td>[If in 2001, you bought $399 of Apple stock in...</td>\n",
       "      <td>62 - 399 - blowout - authorizes - ipod - origi...</td>\n",
       "      <td>0.548841</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Historically it's way better to invest at mark...</td>\n",
       "      <td>309</td>\n",
       "      <td>309_historically_occur_overnight_open</td>\n",
       "      <td>[historically, occur, overnight, open, better,...</td>\n",
       "      <td>[Historically it's way better to invest at mar...</td>\n",
       "      <td>historically - occur - overnight - open - bett...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>Deutsche Bank hit with $150 million penalty fo...</td>\n",
       "      <td>168</td>\n",
       "      <td>168_sex_epstein_deutsche_jeffrey</td>\n",
       "      <td>[sex, epstein, deutsche, jeffrey, offender, fa...</td>\n",
       "      <td>[Deutsche Bank hit with $150 million penalty f...</td>\n",
       "      <td>sex - epstein - deutsche - jeffrey - offender ...</td>\n",
       "      <td>0.584507</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>JPMorgan is stopping financing of private pris...</td>\n",
       "      <td>30</td>\n",
       "      <td>30_jpmorgan_advises_detention_centers</td>\n",
       "      <td>[jpmorgan, advises, detention, centers, expose...</td>\n",
       "      <td>[JPMorgan is stopping financing of private pri...</td>\n",
       "      <td>jpmorgan - advises - detention - centers - exp...</td>\n",
       "      <td>0.186540</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>Warren Buffett, as always, looks like the smar...</td>\n",
       "      <td>93</td>\n",
       "      <td>93_always_smartest_room_doing</td>\n",
       "      <td>[always, smartest, room, doing, mr, guy, buffe...</td>\n",
       "      <td>[Warren Buffett, as always, looks like the sma...</td>\n",
       "      <td>always - smartest - room - doing - mr - guy - ...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>Warren Buffett's Berkshire Hathaway sells 12.9...</td>\n",
       "      <td>42</td>\n",
       "      <td>42_hathaway_berkshire_sells_9m</td>\n",
       "      <td>[hathaway, berkshire, sells, 9m, 3m, southwest...</td>\n",
       "      <td>[Warren Buffett's Berkshire Hathaway sells 12....</td>\n",
       "      <td>hathaway - berkshire - sells - 9m - 3m - south...</td>\n",
       "      <td>0.838299</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>Berkshire Hathaway beats Q4 EPS Consensus by 4...</td>\n",
       "      <td>201</td>\n",
       "      <td>201_repurchases_consensus_snapped_barrick</td>\n",
       "      <td>[repurchases, consensus, snapped, barrick, 563...</td>\n",
       "      <td>[Berkshire Hathaway beats Q4 EPS Consensus by ...</td>\n",
       "      <td>repurchases - consensus - snapped - barrick - ...</td>\n",
       "      <td>0.801092</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Document  Topic  \\\n",
       "0     Robinhood and other brokers literally blocking...    151   \n",
       "1     United Airlines stock down over 5% premarket t...    191   \n",
       "2           Bitcoin was nearly $20,000 a year ago today    287   \n",
       "3     If in 2001, you bought $399 of Apple stock ins...    179   \n",
       "4     Historically it's way better to invest at mark...    309   \n",
       "...                                                 ...    ...   \n",
       "9995  Deutsche Bank hit with $150 million penalty fo...    168   \n",
       "9996  JPMorgan is stopping financing of private pris...     30   \n",
       "9997  Warren Buffett, as always, looks like the smar...     93   \n",
       "9998  Warren Buffett's Berkshire Hathaway sells 12.9...     42   \n",
       "9999  Berkshire Hathaway beats Q4 EPS Consensus by 4...    201   \n",
       "\n",
       "                                           Name  \\\n",
       "0                151_thread_broker_popular_hate   \n",
       "1                191_united_airlines_ual_planes   \n",
       "2               287_cathy_crispr_invitae_square   \n",
       "3                 179_62_399_blowout_authorizes   \n",
       "4         309_historically_occur_overnight_open   \n",
       "...                                         ...   \n",
       "9995           168_sex_epstein_deutsche_jeffrey   \n",
       "9996      30_jpmorgan_advises_detention_centers   \n",
       "9997              93_always_smartest_room_doing   \n",
       "9998             42_hathaway_berkshire_sells_9m   \n",
       "9999  201_repurchases_consensus_snapped_barrick   \n",
       "\n",
       "                                         Representation  \\\n",
       "0     [thread, broker, popular, hate, experiencing, ...   \n",
       "1     [united, airlines, ual, planes, events, dragge...   \n",
       "2     [cathy, crispr, invitae, square, predicted, wo...   \n",
       "3     [62, 399, blowout, authorizes, ipod, original,...   \n",
       "4     [historically, occur, overnight, open, better,...   \n",
       "...                                                 ...   \n",
       "9995  [sex, epstein, deutsche, jeffrey, offender, fa...   \n",
       "9996  [jpmorgan, advises, detention, centers, expose...   \n",
       "9997  [always, smartest, room, doing, mr, guy, buffe...   \n",
       "9998  [hathaway, berkshire, sells, 9m, 3m, southwest...   \n",
       "9999  [repurchases, consensus, snapped, barrick, 563...   \n",
       "\n",
       "                                    Representative_Docs  \\\n",
       "0     [Robinhood says it’s experiencing a ‘system-wi...   \n",
       "1     [A Month Ago, United Airlines Stock Dropped By...   \n",
       "2     [Cathy Wood predicted Bitcoin, Tesla, Square, ...   \n",
       "3     [If in 2001, you bought $399 of Apple stock in...   \n",
       "4     [Historically it's way better to invest at mar...   \n",
       "...                                                 ...   \n",
       "9995  [Deutsche Bank hit with $150 million penalty f...   \n",
       "9996  [JPMorgan is stopping financing of private pri...   \n",
       "9997  [Warren Buffett, as always, looks like the sma...   \n",
       "9998  [Warren Buffett's Berkshire Hathaway sells 12....   \n",
       "9999  [Berkshire Hathaway beats Q4 EPS Consensus by ...   \n",
       "\n",
       "                                            Top_n_words  Probability  \\\n",
       "0     thread - broker - popular - hate - experiencin...     0.746662   \n",
       "1     united - airlines - ual - planes - events - dr...     0.965646   \n",
       "2     cathy - crispr - invitae - square - predicted ...     0.904166   \n",
       "3     62 - 399 - blowout - authorizes - ipod - origi...     0.548841   \n",
       "4     historically - occur - overnight - open - bett...     1.000000   \n",
       "...                                                 ...          ...   \n",
       "9995  sex - epstein - deutsche - jeffrey - offender ...     0.584507   \n",
       "9996  jpmorgan - advises - detention - centers - exp...     0.186540   \n",
       "9997  always - smartest - room - doing - mr - guy - ...     1.000000   \n",
       "9998  hathaway - berkshire - sells - 9m - 3m - south...     0.838299   \n",
       "9999  repurchases - consensus - snapped - barrick - ...     0.801092   \n",
       "\n",
       "      Representative_document  \n",
       "0                       False  \n",
       "1                       False  \n",
       "2                       False  \n",
       "3                        True  \n",
       "4                        True  \n",
       "...                       ...  \n",
       "9995                     True  \n",
       "9996                     True  \n",
       "9997                     True  \n",
       "9998                     True  \n",
       "9999                     True  \n",
       "\n",
       "[10000 rows x 8 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model.get_document_info(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "845595e6-4499-41a7-925a-d1cc9b2dcde5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from bertopic.representation import KeyBERTInspired\n",
    "\n",
    "# Fine-tune your topic representations\n",
    "representation_model = KeyBERTInspired()\n",
    "topic_model = BERTopic(representation_model=representation_model)\n",
    "topics, probs = topic_model.fit_transform(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e849fd94-2bd0-4e2c-a668-d0fdb287700c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "      <th>Representation</th>\n",
       "      <th>Representative_Docs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1756</td>\n",
       "      <td>0_about_who_just_than</td>\n",
       "      <td>[about, who, just, than, more, we, new, has, b...</td>\n",
       "      <td>[This was posted by Lyn Bates to the firearms-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>188</td>\n",
       "      <td>1_baseball_players_nhl_league</td>\n",
       "      <td>[baseball, players, nhl, league, player, hocke...</td>\n",
       "      <td>[\\nI agree that Keenan is an excellent choice....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>56</td>\n",
       "      <td>2____</td>\n",
       "      <td>[, , , , , , , , , ]</td>\n",
       "      <td>[\\n, was...\\n, hello testing\\n\\n\\n]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic  Count                           Name  \\\n",
       "0      0   1756          0_about_who_just_than   \n",
       "1      1    188  1_baseball_players_nhl_league   \n",
       "2      2     56                          2____   \n",
       "\n",
       "                                      Representation  \\\n",
       "0  [about, who, just, than, more, we, new, has, b...   \n",
       "1  [baseball, players, nhl, league, player, hocke...   \n",
       "2                               [, , , , , , , , , ]   \n",
       "\n",
       "                                 Representative_Docs  \n",
       "0  [This was posted by Lyn Bates to the firearms-...  \n",
       "1  [\\nI agree that Keenan is an excellent choice....  \n",
       "2                [\\n, was...\\n, hello testing\\n\\n\\n]  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f54dfaa7-0140-45f4-9d0a-881e1079eb42",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('about', 0.22966816),\n",
       " ('who', 0.1520166),\n",
       " ('just', 0.15114468),\n",
       " ('than', 0.14497769),\n",
       " ('more', 0.13656455),\n",
       " ('we', 0.13589157),\n",
       " ('new', 0.1306823),\n",
       " ('has', 0.12739609),\n",
       " ('be', 0.12285234),\n",
       " ('because', 0.1181923)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model.get_topic(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a22231a-7087-4612-a5a4-8b449e7ad188",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from bertopic.representation import PartOfSpeech\n",
    "from bertopic import BERTopic\n",
    "\n",
    "# Create your representation model\n",
    "representation_model = PartOfSpeech(\"en_core_web_sm\")\n",
    "\n",
    "# Use the representation model in BERTopic on top of the default pipeline\n",
    "topic_model = BERTopic(representation_model=representation_model)\n",
    "topics, probs = topic_model.fit_transform(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "103794a1-0fea-4bcc-adf6-a7d7f365f786",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "      <th>Representation</th>\n",
       "      <th>Representative_Docs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1755</td>\n",
       "      <td>0_will_one_people_other</td>\n",
       "      <td>[will, one, people, other, use, time, new, suc...</td>\n",
       "      <td>[Archive-name: x-faq/speedups\\nLast-modified: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>188</td>\n",
       "      <td>1_game_team_year_games</td>\n",
       "      <td>[game, team, year, games, up, time, players, h...</td>\n",
       "      <td>[\\nI agree that Keenan is an excellent choice....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>57</td>\n",
       "      <td>2_testing___</td>\n",
       "      <td>[testing, , , , , , , , , ]</td>\n",
       "      <td>[was...\\n,  \\n(Deletion)\\n , hello testing\\n\\n\\n]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic  Count                     Name  \\\n",
       "0      0   1755  0_will_one_people_other   \n",
       "1      1    188   1_game_team_year_games   \n",
       "2      2     57             2_testing___   \n",
       "\n",
       "                                      Representation  \\\n",
       "0  [will, one, people, other, use, time, new, suc...   \n",
       "1  [game, team, year, games, up, time, players, h...   \n",
       "2                        [testing, , , , , , , , , ]   \n",
       "\n",
       "                                 Representative_Docs  \n",
       "0  [Archive-name: x-faq/speedups\\nLast-modified: ...  \n",
       "1  [\\nI agree that Keenan is an excellent choice....  \n",
       "2  [was...\\n,  \\n(Deletion)\\n , hello testing\\n\\n\\n]  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d126496-c35d-4332-a641-54a8e4ec5b5e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\nI agree that Keenan is an excellent choice.  Did you see Mike\\nLupica\\'s column in Sunday\\'s news?  My sentiments exactly.  I\\nthink he just may be the one to instill some hunger and fire\\ninto their hearts next season.  Either that or he\\'s going to \\nbe kicking alot of butt!\\n\\n\\nI\\'m here, but am new to this group and have been keeping fairly\\nquiet (you know, doing the \"lurking\" thing).  I don\\'t have a\\nsense how many Rangers fans there are on the list either.  I \\nam a die-hard Ranger fan (I guess I have to be - I sat in the\\nGarden throughout the Penguins\\' - led by Mario\\'s 5 goals - decimation \\nof them on 4/9), but am sick at the abundance of talent that has\\nbeen totally untapped, and the lack of heart displayed this\\nseason.\\n\\n\\nHurlbut was injured for quite a while.  I\\'m not sure, but I\\nthink he may have recovered in time for the playoff run, and\\nif so, like you, question why he wasn\\'t used.\\n\\n\\nI believe Kocur was used, in many instances, for his intimidation \\nfactor.  Granted, he seemed to get an awful lot of ice time for \\nthat reason alone, but you have to realize that when a team is\\nnot doing any REAL physical intimidation (I\\'d like to have a nickel \\nfor every time J.D. said \\'They\\'ve got to take the body more\\'), \\nyou\\'ve got to at least have some illusions ;-(\\n\\n\\nI agree and I don\\'t know.\\n\\n\\nSorry, I don\\'t agree with you here.  I think Joey C. did a good\\njob filling in when he was asked to.  I can\\'t imagine that it\\'s\\neasy going from near 0 ice time to being a full timer.  I don\\'t\\nseem to remember him turning the puck over at the blue line too\\nmuch, or failing to clear the zone.  He worked hard, and at\\nleast didn\\'t make any rookie mistakes.  As he said himself in an\\ninterview, he can only give what he has.  and he did.  \\n\\n\\nAbsolutely.  I think attendance at the Garden was better on the\\nlast day of the season, than any average night for the\\nIslanders.\\n\\n\\nThe man is awesome.  In a way, I\\'m enjoying the playoffs more,\\nnow that the Rangers aren\\'t in them.  I can really appreciate\\nall the glory Mario is getting without \\'hating\\' him because he\\'s\\non the opposing team.  He deserves it all, as far as I\\'m\\nconcerned.\\n\\n\\t\\t- Mary',\n",
       " 'I hope that this comes off as a somewhat unbiased assesment\\nof WFAN and WIP(I go to school in Philadelphia, and I listen to\\nboth stations on a consistant basis.)  Now that the fan has Mike\\nLupica on from 10 to noon, they have a person who can get the \\nbig name guests for interviews, and not just of local importance\\nHe did have Dave Cheketts and Fred Wilpon on his show, but he \\nhad Bob Costas and Magic Johnson on too.  \\n  Now here are my opinions of the two stations competing talent:\\nMorning show:\\n  In my opinion, I think Imus is much better than Bruno, Cataldi, \\nand Morganti, even though I would feel different if Morganti\\nhad a better crew of people to work with.  To me, WIP tries\\nto copy Imus but make it all sports as a theme.  In terms of\\nsports, Imus lacks the blanketing of the airwaves, but he\\ninterjects humor and politics into his show.\\n10 AM to 12 Noon:\\n  I think Chuck Cooperstein and Lupica are equal in their\\nabilities to host a radio show, but I think Chuck has the\\nadvantage over Lupica in terms of dealing with the caller\\nwho is asking about who the local team is going to draft\\nin the sixth round.  Lupica and the other hosts on FAN get\\nbetter interview guests, but I heard the PD of WIP say that\\nthey were not interested in interviews with celebrities unless\\nit was a major story.\\n  I would consider this even because they are two different\\nstyles of host.\\n\\n12 Noon to 2 PM:\\n  At this point, I would have to give a big advantage to \\nJody McDonald over Len Berman because Lenny has only been\\non for a couple of weeks.  I just think JM has the ability\\nto transcend the \"homer\" mentality of the Philadelphia fan\\nbase.  This is most evident when the IGGLES(Philadelphia \\nspelling) play the Cowboys because JM is a huge Dallas fan.\\nWhere else can you have people call up and predict a 93-0\\nscore without the egging of the hosts(re:WIP morning \\'guys\\')\\nI do agree that JM was great on the FAN weekend overnight\\nand I miss hearing him over the current crop of rotating\\nhosts.  I feel that JM is the best sportstalk host on \\neither station by a good margin.  If you are in NY and\\nyou can\\'t get WIP, JM does fill in on the weekends sometimes.\\n\\n2PM to 4PM:\\n  This is the time when JM goes up against Francesa and \\nRusso(fatso and froot loops) and I become the most divided\\nin my loyalties.  Mike and the dog are very entertaining,\\nbut they often go an hour or so without calls or even 10\\nto 20 minutes without talking about sports.  MATD do\\nget great guests and that is the basis for their show, so\\nit is like the 10 to 12 debate.  Another plus is the\\nappearances by Mike and Chris on Imus in the Morning, which\\nare often hilarious.  \\n\\n4 PM to 7 PM:\\n  MATD go up against Fredericks and Missanelli.  I like\\nMike Missanelli but I just can\\'t stomach Steve Fredericks.  \\nI know that SF came from Philly originally, but when he\\nwas at the FAN, he was a NY homer as much as he is a Philly\\nhomer now.  I don\\'t listen to WIP much after 4 PM unless there\\nis a game on that night, but you will see later for the \\nreason.  That is why I give the advantage to FAN.\\n\\n7 PM to Midnight:\\n  S&M are on WIP until 8 and then it is the man who makes\\nEli that calls MATD all the time seem like a novice on\\ncharges of racism, G Cobb.  This man is so grating on my\\nnerves that if I listen to him for a few minutes I go\\nnuts.(I know that is biased, but listen to his show)\\nOn FAN, there is usually a game on, Knicks, Rangers, Mets\\nJets, or St. John\\'s basketball.  If the game is on the\\nwest coast, then it is usually Howie Rose.  Of course\\nI think dead air would be better than G Cobb on WIP, but\\nWIP does air Sixers and Flyers games during the season.\\n(If this is the sports station, why did they lose the\\nIGGLES to WYSP(home of Howard Stern in Phil.))\\nDuring the summer, it\\nis all talk on WIP.\\n\\n\\nOverall, I would have to give the advantage to WFAN, with\\nthe exception of 10 to 12, and 2 to 4 where it is even, and\\n12 to 2 where WIP has the advantage.   \\n\\n\\n\\n            Rich',\n",
       " 'Note:  I\\'m not posting this as part of an argument with Roger Meynard,\\nbut as an independent sort of thread.  I do actually quote some things\\nthat Roger Meynard wrote, but it might be better to think of this as\\n\"sampling\" his post (in the hip-hop sense) because it fits in with what\\nI want to say.\\n\\n\\nThere\\'s an interesting parallel between this way of viewing a baseball\\nteam and some people\\'s conception of a biological organism.  In the\\nbiology context, we would very likely read \"fitness\" for \"the score of\\nthe game\" and \"organisms\" for \"teams\".  How we interpret \"players\" is\\ntrickier, but either \"organs\", or \"genes\" might seem reasonable\\nchoices depending on what point we were trying to make.  A \"genes\"\\ninterpretation actually might be really interesting in this case, \\nbut that would be a different and probably longer post.\\n\\nIf, however, we take the \"organ\" view, then our knowledge of biology\\nshould make us pause before we start saying things like \"species X is\\nmore fit than species Y because of a better organ Z\".  Given what we\\nknow about the interdependence of organs, we would often be suspicious\\nof such claims.  (But note that this type of argument is quite often\\nmade when you map \"species X\" onto \\'humans\\', and \"organ Z\" onto\\n\\'brain\\').  On the other hand, some statements of this kind do seem\\nmore reasonable than others, as far as we can test them (e.g. \\'brain\\'\\nabove might be more reasonable than \\'pancreas\\' assuming no gross\\npathology, particularly if species Y is a primate).\\n\\nEven when you make such statements, you should be concerned with the\\nfunctioning of the whole organism, and the possibility that one organ\\nmight be more crucial for one species and a second organ in another.\\n(Not to mention the possibility that no organ is particularly crucial\\nin some third species.)  However, if we are non-vitalists with any\\nkind of reductionsit streak, we will want to say that an organism is\\nnot some completely magical unanalyzable \"whole\" but an intriguing\\nprocess made up of various subprocesses that interact in ways that are\\npotentially observable.  Some of these processes might be localized to\\nparticular organs, while others may be distributed across multiple\\norgans.  In a way, this is just like a baseball team, except that I\\nthink it is pretty clear that the processes and interactions involved\\nin baseball are *much* simpler and less numerous than in most organisms.\\n\\n\\nOne thing that is quite difficult about baseball is that perfectly\\ncontrolled experiments are sometimes very tough to do.  But, of\\ncourse, this has never stopped researchers from doing the best they\\ncan, and sometimes deriving very powerful conclusions even in the\\nabsence of certainty.  Most of this goes far beyond sheer speculation,\\nbut even sheer speculation can motivate further interesting research.\\n\\n\\nIn this cases, we\\'re seeing the word \"statistics\" means \"summary of\\nobserved events\", where the events themselves can be viewed as the\\noutput of some process, and possibly inputs for other processes.\\nThus, if we have any valid notion of how the processes are put together\\ninto the functioning organism, data in the form of statistics might\\ngive us a basis to test particular hypotheses.\\n\\n\\nThis statement brings us back to the concept of fitness again.\\nFitness is defined in terms of both an organism and its environment;\\nyou might be fit in one situation and not another.  Moving to\\nbaseball, it is clear that each team spends the entire season in an\\nenvironment including all the other teams in the league.  In at least\\na nominal sense, the division winners are the fittest teams in the\\nleague, in that they (on average) had better fitness scores than any\\nof their competing opponennts.  But in a real sense, there is a fairly\\nlarge random component in the performance of each team that is\\ndifficult if not impossible to account for in terms of factors\\nintrinsic to (or interesting for) baseball.  The same is true in\\nbiology.  But here is also no direct biological equivalent of the\\nWorld Series in basebal.  In the world series, the random component\\nmay be greatly magnified by the small number of games that are played,\\nand both teams suddenly experience huge changes from the environement\\nwhere they were originally successful.  It might be fun to watch, but\\nit\\'s unclear what it all really means.\\n\\n***\\n\\nNow just one more un-related point:\\n\\n\\nOn the other hand, you have seen some of us who can predict the\\noutcome of the divisional races better than a random assignment of\\nteams to finishes, and maybe some of us (e.g. me) who can do this\\nbetter than the other participants in this forum on a regular basis.\\nBut this is probably only due to the fact that a 162-game schedule\\ngives you a little hope that bad hops aren\\'t the only difference\\nbetween the winners and the losers.\\n\\nMoreover, you\\'ve had the opportunity to see some analysis of the World\\nSeries situation that makes the strong claim that *nobody* can predict\\nthe WS winner with reliably greater accuracy than a coin biased only\\nto reflect the well-known home vs. road effect on winning percentage.\\n\\n\\nSince stats are summaries of events, it\\'s true that if you know the\\nevents you can derive the stats.  But if somebody is trying to\\nunderstand the process behind the stats, then the stats produce new\\nknowledge, and some of this might even be reliable, repeatable, and\\nuseful.  Speaking of which, I should get back to producing knowledge\\nin a different field.  That is, of course, if I can produce knowledge\\neven though I\\'m relying on stats to do it.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model.get_representative_docs(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3d152f-9063-4482-b250-f0253df60cb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l:Python",
   "language": "python",
   "name": "conda-env-d2l-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
