{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "067a0c59-b4c5-4e6e-8dfb-104e75ec16b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import praw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ab656ab-1c31-4f0c-a78a-9e17ad2eccdf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reddit = praw.Reddit(client_id='Qwx1ivHVWBXz1sjn6KhgOA', client_secret='dv13_B2LkUhRrSdwhIuyX5PfMUeuFA', user_agent='lucipraw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d39b6c3d-0986-4fdd-875e-23218e3ba1b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "990\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "posts = []\n",
    "invest_subreddit = reddit.subreddit('Investing')\n",
    "for post in invest_subreddit.top(limit=10000):\n",
    "    created_date = datetime.datetime.fromtimestamp(post.created)\n",
    "    posts.append([post.title, post.score, post.id, post.subreddit, post.num_comments, post.selftext,created_date]) #created_date = datetime.datetime.fromtimestamp(post.created)])\n",
    "posts = pd.DataFrame(posts,columns=['title', 'score', 'id', 'subreddit', 'num_comments', 'body', 'created'])\n",
    "#print(posts)\n",
    "posts.to_csv('reddit_scraped3.csv', index=False)\n",
    "print(len(posts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c06e12ee-2179-4805-ab08-8fca5b21270e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_old=pd.read_csv('reddit_scraped10000.csv')\n",
    "posts = []\n",
    "stocks_subreddit = reddit.subreddit('stocks')\n",
    "for post in stocks_subreddit.hot(limit=100000):\n",
    "    created_date = datetime.datetime.fromtimestamp(post.created)\n",
    "    posts.append([post.title, post.score, post.id, post.subreddit, post.num_comments, post.selftext,created_date]) #created_date = datetime.datetime.fromtimestamp(post.created)])\n",
    "posts = pd.DataFrame(posts,columns=['title', 'score', 'id', 'subreddit', 'num_comments', 'body', 'created'])\n",
    "combined_data = pd.concat([data_old, posts], ignore_index=True)\n",
    "#print(combined_data)\n",
    "combined_data.to_csv('reddit_scraped10000.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f34f2dd2-233f-4837-bc3d-cac5b10c270d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total posts fetched: 100000\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import praw\n",
    "import time\n",
    "\n",
    "# Define parameters\n",
    "subreddit_name = 'Investing'\n",
    "total_posts_to_fetch = 100000  # Total number of posts to fetch\n",
    "wait_time_seconds = 1  # Time to wait between requests (to handle rate limits)\n",
    "\n",
    "# Initialize empty list to store post data\n",
    "posts = []\n",
    "\n",
    "# Extract data\n",
    "invest_subreddit = reddit.subreddit(subreddit_name)\n",
    "\n",
    "total_posts_fetched = 0\n",
    "while total_posts_fetched < total_posts_to_fetch:\n",
    "    try:\n",
    "        # Fetch posts\n",
    "        for post in invest_subreddit.top(limit=min(1000, total_posts_to_fetch - total_posts_fetched)):\n",
    "            created_date = datetime.datetime.fromtimestamp(post.created)\n",
    "            posts.append([post.title, post.score, post.id, post.subreddit, post.num_comments, post.selftext, created_date])\n",
    "            total_posts_fetched += 1\n",
    "            \n",
    "        # Wait before making the next request\n",
    "        time.sleep(wait_time_seconds)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "        # Optionally, handle the error and retry or exit the loop\n",
    "\n",
    "# Create a pandas DataFrame from the collected data\n",
    "df = pd.DataFrame(posts, columns=['title', 'score', 'id', 'subreddit', 'num_comments', 'body', 'created'])\n",
    "\n",
    "# Optionally, you can write the DataFrame to a CSV file\n",
    "df.to_csv('reddit_scraped_all_10k.csv', index=False)\n",
    "\n",
    "print(\"Total posts fetched:\", len(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3411c4d7-e1ac-4796-aa7f-437eb645c6d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total posts fetched: 100000\n",
      "CPU times: user 27.1 s, sys: 669 ms, total: 27.7 s\n",
      "Wall time: 28min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "subreddit_name = 'Stocks'\n",
    "total_posts_to_fetch = 100000  # Total number of posts to fetch\n",
    "wait_time_seconds = 1  # Time to wait between requests (to handle rate limits)\n",
    "\n",
    "# Initialize empty list to store post data\n",
    "posts = []\n",
    "\n",
    "# Extract data\n",
    "invest_subreddit = reddit.subreddit(subreddit_name)\n",
    "\n",
    "total_posts_fetched = 0\n",
    "while total_posts_fetched < total_posts_to_fetch:\n",
    "    try:\n",
    "        # Fetch posts\n",
    "        for post in invest_subreddit.top(limit=min(1000, total_posts_to_fetch - total_posts_fetched)):\n",
    "            created_date = datetime.datetime.fromtimestamp(post.created)\n",
    "            posts.append([post.title, post.score, post.id, post.subreddit, post.num_comments, post.selftext, created_date])\n",
    "            total_posts_fetched += 1\n",
    "            \n",
    "        # Wait before making the next request\n",
    "        time.sleep(wait_time_seconds)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "        # Optionally, handle the error and retry or exit the loop\n",
    "\n",
    "# Create a pandas DataFrame from the collected data\n",
    "df = pd.DataFrame(posts, columns=['title', 'score', 'id', 'subreddit', 'num_comments', 'body', 'created'])\n",
    "\n",
    "\n",
    "# Optionally, you can write the DataFrame to a CSV file\n",
    "df.to_csv('reddit_scraped_100k.csv', index=False)\n",
    "\n",
    "print(\"Total posts fetched:\", len(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68a2d8c4-1f67-49ad-9952-a44c5c8a642e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV files combined successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Read the CSV files into DataFrames\n",
    "df1 = pd.read_csv('reddit_scraped_100k.csv')\n",
    "df2 = pd.read_csv('combined_file.csv')\n",
    "\n",
    "# Step 2: Combine the DataFrames using pd.concat\n",
    "combined_df = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "# Step 3: Save the combined DataFrame to a new CSV file\n",
    "combined_df.to_csv('combined_file.csv', index=False)\n",
    "\n",
    "print(\"CSV files combined successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a837907e-4153-447c-9d6d-c23a7da17e3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "shuffled_df = combined_df.sample(frac=1).reset_index(drop=True)\n",
    "shuffled_df.to_csv('combined_file.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2c02d86a-516a-40ec-b6e8-a3bf64a3e944",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300010, 8)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('combined_file.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "12737dea-fe2c-4327-b8e0-ecbd2023300d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_old=pd.read_csv('reddit_scraped10000.csv')\n",
    "posts = []\n",
    "stk_mkt_subreddit = reddit.subreddit('StockMarket')\n",
    "for post in stk_mkt_subreddit.hot(limit=100000):\n",
    "    created_date = datetime.datetime.fromtimestamp(post.created)\n",
    "    posts.append([post.title, post.score, post.id, post.subreddit, post.num_comments, post.selftext,created_date]) #created_date = datetime.datetime.fromtimestamp(post.created)])\n",
    "posts = pd.DataFrame(posts,columns=['title', 'score', 'id', 'subreddit', 'num_comments', 'body', 'created'])\n",
    "combined_data = pd.concat([data_old, posts], ignore_index=True)\n",
    "#print(combined_data)\n",
    "combined_data.to_csv('reddit_scraped10000.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7ca987b2-c927-4032-a3ba-53bb3cd4ff46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_old=pd.read_csv('reddit_scraped10000.csv')\n",
    "posts = []\n",
    "crypto_subreddit = reddit.subreddit('CryptoMarkets')\n",
    "for post in crypto_subreddit.hot(limit=100000):\n",
    "    created_date = datetime.datetime.fromtimestamp(post.created)\n",
    "    posts.append([post.title, post.score, post.id, post.subreddit, post.num_comments, post.selftext,created_date]) #created_date = datetime.datetime.fromtimestamp(post.created)])\n",
    "posts = pd.DataFrame(posts,columns=['title', 'score', 'id', 'subreddit', 'num_comments', 'body', 'created'])\n",
    "combined_data = pd.concat([data_old, posts], ignore_index=True)\n",
    "#print(combined_data)\n",
    "combined_data.to_csv('reddit_scraped10000.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0da03192-ade8-4ba8-9bd4-e599b237d918",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_old=pd.read_csv('reddit_scraped10000.csv')\n",
    "posts = []\n",
    "pol_subreddit = reddit.subreddit('politics')\n",
    "for post in pol_subreddit.hot(limit=100000):\n",
    "    created_date = datetime.datetime.fromtimestamp(post.created)\n",
    "    posts.append([post.title, post.score, post.id, post.subreddit, post.num_comments, post.selftext,created_date]) #created_date = datetime.datetime.fromtimestamp(post.created)])\n",
    "posts = pd.DataFrame(posts,columns=['title', 'score', 'id', 'subreddit', 'num_comments', 'body', 'created'])\n",
    "combined_data = pd.concat([data_old, posts], ignore_index=True)\n",
    "#print(combined_data)\n",
    "combined_data.to_csv('reddit_scraped10000.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3a9466f3-23ea-4c0c-b692-23b55afacdd6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_old=pd.read_csv('reddit_scraped10000.csv')\n",
    "posts = []\n",
    "busi_subreddit = reddit.subreddit('business')\n",
    "for post in busi_subreddit.hot(limit=100000):\n",
    "    created_date = datetime.datetime.fromtimestamp(post.created)\n",
    "    posts.append([post.title, post.score, post.id, post.subreddit, post.num_comments, post.selftext,created_date]) #created_date = datetime.datetime.fromtimestamp(post.created)])\n",
    "posts = pd.DataFrame(posts,columns=['title', 'score', 'id', 'subreddit', 'num_comments', 'body', 'created'])\n",
    "combined_data = pd.concat([data_old, posts], ignore_index=True)\n",
    "#print(combined_data)\n",
    "combined_data.to_csv('reddit_scraped10000.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6a0c6450-3508-425c-9bbd-b170921987a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_old=pd.read_csv('reddit_scraped10000.csv')\n",
    "posts = []\n",
    "wn_subreddit = reddit.subreddit('worldnews')\n",
    "for post in wn_subreddit.hot(limit=100000):\n",
    "    created_date = datetime.datetime.fromtimestamp(post.created)\n",
    "    posts.append([post.title, post.score, post.id, post.subreddit, post.num_comments, post.selftext,created_date]) #created_date = datetime.datetime.fromtimestamp(post.created)])\n",
    "posts = pd.DataFrame(posts,columns=['title', 'score', 'id', 'subreddit', 'num_comments', 'body', 'created'])\n",
    "combined_data = pd.concat([data_old, posts], ignore_index=True)\n",
    "#print(combined_data)\n",
    "combined_data.to_csv('reddit_scraped10000.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "593b5941-e042-4e73-a928-02e260518f16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_shuffled = combined_data.sample(frac=1).reset_index(drop=True)\n",
    "#print(df_shuffled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "214db32b-b3fd-4d3c-b180-c1fcc6f8aba9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "      <th>id</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>body</th>\n",
       "      <th>created</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Meet Trump’s ‘human printer’ who claims he cur...</td>\n",
       "      <td>0</td>\n",
       "      <td>1cyzwvw</td>\n",
       "      <td>politics</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-05-23 18:28:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How long after the ex-Date can I sell a Stock?</td>\n",
       "      <td>0</td>\n",
       "      <td>1cwuvmq</td>\n",
       "      <td>stocks</td>\n",
       "      <td>34</td>\n",
       "      <td>I have been trying to lock in Dividend payment...</td>\n",
       "      <td>2024-05-21 00:26:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>At least 24 dead, mostly children, in India am...</td>\n",
       "      <td>217</td>\n",
       "      <td>1d0sl4b</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>17</td>\n",
       "      <td></td>\n",
       "      <td>2024-05-26 03:30:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Is DYDX Crypto due for a Breakout: DYDX Crypto...</td>\n",
       "      <td>6</td>\n",
       "      <td>1czrn8y</td>\n",
       "      <td>CryptoMarkets</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-05-24 18:26:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Technical analysis</td>\n",
       "      <td>0</td>\n",
       "      <td>1ci8xa9</td>\n",
       "      <td>CryptoMarkets</td>\n",
       "      <td>16</td>\n",
       "      <td>Hello everyone, I hope you are well. Any books...</td>\n",
       "      <td>2024-05-02 06:39:58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  score       id  \\\n",
       "0  Meet Trump’s ‘human printer’ who claims he cur...      0  1cyzwvw   \n",
       "1     How long after the ex-Date can I sell a Stock?      0  1cwuvmq   \n",
       "2  At least 24 dead, mostly children, in India am...    217  1d0sl4b   \n",
       "3  Is DYDX Crypto due for a Breakout: DYDX Crypto...      6  1czrn8y   \n",
       "4                                 Technical analysis      0  1ci8xa9   \n",
       "\n",
       "       subreddit  num_comments  \\\n",
       "0       politics            14   \n",
       "1         stocks            34   \n",
       "2      worldnews            17   \n",
       "3  CryptoMarkets             1   \n",
       "4  CryptoMarkets            16   \n",
       "\n",
       "                                                body              created  \n",
       "0                                                NaN  2024-05-23 18:28:30  \n",
       "1  I have been trying to lock in Dividend payment...  2024-05-21 00:26:05  \n",
       "2                                                     2024-05-26 03:30:23  \n",
       "3                                                NaN  2024-05-24 18:26:55  \n",
       "4  Hello everyone, I hope you are well. Any books...  2024-05-02 06:39:58  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_shuffled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02f5abd-b1ae-4281-a336-d892d7c04862",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
