{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7312ee58-a845-4d03-9ba6-254091dd45c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e475185d-827d-4b95-8c48-86f5fe922eae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5da0058b-e3ea-4a18-847e-f63b51b4cf17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('reddit_scraped10000-Copy1.csv')\n",
    "\n",
    "# Split dataset into training and test sets\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    df['title'], df['subreddit'], test_size=0.2, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "51732d40-27ad-4f9e-b266-376f67cac59e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Tokenize the data\n",
    "train_encodings = tokenizer(list(train_texts), truncation=True, padding=True)\n",
    "test_encodings = tokenizer(list(test_texts), truncation=True, padding=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4781f50a-0d52-4ffc-9df9-c7a53904d78f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "# Create the dataset objects\n",
    "train_dataset = Dataset(train_encodings, train_labels.tolist())\n",
    "test_dataset = Dataset(test_encodings, test_labels.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e7643f2-7c81-4a7a-a76b-ab6d3acb750b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /home/studio-lab-user/.conda/envs/d2l/lib/python3.9/site-packages (1.8.1)\n",
      "Requirement already satisfied: torchvision in /home/studio-lab-user/.conda/envs/d2l/lib/python3.9/site-packages (0.9.1)\n",
      "Collecting torchaudio\n",
      "  Downloading torchaudio-2.3.0-cp39-cp39-manylinux1_x86_64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: typing-extensions in /home/studio-lab-user/.conda/envs/d2l/lib/python3.9/site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: numpy in /home/studio-lab-user/.conda/envs/d2l/lib/python3.9/site-packages (from torch) (1.26.4)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /home/studio-lab-user/.conda/envs/d2l/lib/python3.9/site-packages (from torchvision) (10.3.0)\n",
      "INFO: pip is looking at multiple versions of torchaudio to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading torchaudio-2.2.2-cp39-cp39-manylinux1_x86_64.whl.metadata (6.4 kB)\n",
      "  Downloading torchaudio-2.2.1-cp39-cp39-manylinux1_x86_64.whl.metadata (6.4 kB)\n",
      "  Downloading torchaudio-2.2.0-cp39-cp39-manylinux1_x86_64.whl.metadata (6.4 kB)\n",
      "  Downloading torchaudio-2.1.2-cp39-cp39-manylinux1_x86_64.whl.metadata (6.4 kB)\n",
      "  Downloading torchaudio-2.1.1-cp39-cp39-manylinux1_x86_64.whl.metadata (6.4 kB)\n",
      "  Downloading torchaudio-2.1.0-cp39-cp39-manylinux1_x86_64.whl.metadata (5.7 kB)\n",
      "  Downloading torchaudio-2.0.2-cp39-cp39-manylinux1_x86_64.whl.metadata (1.2 kB)\n",
      "INFO: pip is still looking at multiple versions of torchaudio to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading torchaudio-2.0.1-cp39-cp39-manylinux1_x86_64.whl.metadata (1.2 kB)\n",
      "  Downloading torchaudio-0.13.1-cp39-cp39-manylinux1_x86_64.whl.metadata (1.2 kB)\n",
      "  Downloading torchaudio-0.13.0-cp39-cp39-manylinux1_x86_64.whl.metadata (1.0 kB)\n",
      "  Downloading torchaudio-0.12.1-cp39-cp39-manylinux1_x86_64.whl.metadata (1.0 kB)\n",
      "  Downloading torchaudio-0.12.0-cp39-cp39-manylinux1_x86_64.whl.metadata (1.0 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Downloading torchaudio-0.11.0-cp39-cp39-manylinux1_x86_64.whl.metadata (1.0 kB)\n",
      "  Downloading torchaudio-0.10.2-cp39-cp39-manylinux1_x86_64.whl.metadata (1.1 kB)\n",
      "  Downloading torchaudio-0.10.1-cp39-cp39-manylinux1_x86_64.whl.metadata (1.1 kB)\n",
      "  Downloading torchaudio-0.10.0-cp39-cp39-manylinux1_x86_64.whl.metadata (1.1 kB)\n",
      "  Downloading torchaudio-0.9.1-cp39-cp39-manylinux1_x86_64.whl.metadata (1.1 kB)\n",
      "  Downloading torchaudio-0.9.0-cp39-cp39-manylinux1_x86_64.whl.metadata (1.1 kB)\n",
      "  Downloading torchaudio-0.8.1-cp39-cp39-manylinux1_x86_64.whl.metadata (1.1 kB)\n",
      "Downloading torchaudio-0.8.1-cp39-cp39-manylinux1_x86_64.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: torchaudio\n",
      "Successfully installed torchaudio-0.8.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c5de761a-c5fd-46f4-87b2-08f90766068f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch' has no attribute 'frombuffer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mBertForSequenceClassification\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbert-base-uncased\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Adjust num_labels as per your classification task\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/d2l/lib/python3.9/site-packages/transformers/modeling_utils.py:3556\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3553\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m from_pt:\n\u001b[1;32m   3554\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_sharded \u001b[38;5;129;01mand\u001b[39;00m state_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3555\u001b[0m         \u001b[38;5;66;03m# Time to load the checkpoint\u001b[39;00m\n\u001b[0;32m-> 3556\u001b[0m         state_dict \u001b[38;5;241m=\u001b[39m \u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresolved_archive_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3558\u001b[0m     \u001b[38;5;66;03m# set dtype to instantiate the model under:\u001b[39;00m\n\u001b[1;32m   3559\u001b[0m     \u001b[38;5;66;03m# 1. If torch_dtype is not None, we use that dtype\u001b[39;00m\n\u001b[1;32m   3560\u001b[0m     \u001b[38;5;66;03m# 2. If torch_dtype is \"auto\", we auto-detect dtype from the loaded state_dict, by checking its first\u001b[39;00m\n\u001b[1;32m   3561\u001b[0m     \u001b[38;5;66;03m#    weights entry that is of a floating type - we assume all floating dtype weights are of the same dtype\u001b[39;00m\n\u001b[1;32m   3562\u001b[0m     \u001b[38;5;66;03m# we also may have config.torch_dtype available, but we won't rely on it till v5\u001b[39;00m\n\u001b[1;32m   3563\u001b[0m     dtype_orig \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/d2l/lib/python3.9/site-packages/transformers/modeling_utils.py:515\u001b[0m, in \u001b[0;36mload_state_dict\u001b[0;34m(checkpoint_file, is_quantized)\u001b[0m\n\u001b[1;32m    510\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m metadata\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mflax\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmlx\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    511\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[1;32m    512\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe safetensors archive passed at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcheckpoint_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not contain the valid metadata. Make sure \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    513\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou save your model with the `save_pretrained` method.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    514\u001b[0m         )\n\u001b[0;32m--> 515\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msafe_load_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    516\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    517\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    518\u001b[0m         (is_deepspeed_zero3_enabled() \u001b[38;5;129;01mand\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mdistributed\u001b[38;5;241m.\u001b[39mis_initialized() \u001b[38;5;129;01mand\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mdistributed\u001b[38;5;241m.\u001b[39mget_rank() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m (is_fsdp_enabled() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_local_dist_rank_0())\n\u001b[1;32m    520\u001b[0m     ) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_quantized:\n",
      "File \u001b[0;32m~/.conda/envs/d2l/lib/python3.9/site-packages/safetensors/torch.py:313\u001b[0m, in \u001b[0;36mload_file\u001b[0;34m(filename, device)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m safe_open(filename, framework\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m, device\u001b[38;5;241m=\u001b[39mdevice) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m f\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m--> 313\u001b[0m         result[k] \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch' has no attribute 'frombuffer'"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=8) # Adjust num_labels as per your classification task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8ec469f3-4a56-4a66-a8d0-829a7d123f43",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8.1+cu102\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6b3922-20df-4138-9c5f-59b8e7db306c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "93e80bfc-d80a-48da-afc9-0cbf9fe09e28",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.41.1\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "print(transformers.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "85450005-9ecf-4db7-a273-35f50fdbe03f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/studio-lab-user/.conda/envs/d2l/lib/python3.9/site-packages (4.41.1)\n",
      "Requirement already satisfied: filelock in /home/studio-lab-user/.conda/envs/d2l/lib/python3.9/site-packages (from transformers) (3.14.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /home/studio-lab-user/.conda/envs/d2l/lib/python3.9/site-packages (from transformers) (0.23.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/studio-lab-user/.conda/envs/d2l/lib/python3.9/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/studio-lab-user/.conda/envs/d2l/lib/python3.9/site-packages (from transformers) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/studio-lab-user/.conda/envs/d2l/lib/python3.9/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/studio-lab-user/.conda/envs/d2l/lib/python3.9/site-packages (from transformers) (2024.5.15)\n",
      "Requirement already satisfied: requests in /home/studio-lab-user/.conda/envs/d2l/lib/python3.9/site-packages (from transformers) (2.32.2)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /home/studio-lab-user/.conda/envs/d2l/lib/python3.9/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/studio-lab-user/.conda/envs/d2l/lib/python3.9/site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/studio-lab-user/.conda/envs/d2l/lib/python3.9/site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/studio-lab-user/.conda/envs/d2l/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2024.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/studio-lab-user/.conda/envs/d2l/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/studio-lab-user/.conda/envs/d2l/lib/python3.9/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/studio-lab-user/.conda/envs/d2l/lib/python3.9/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/studio-lab-user/.conda/envs/d2l/lib/python3.9/site-packages (from requests->transformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/studio-lab-user/.conda/envs/d2l/lib/python3.9/site-packages (from requests->transformers) (2024.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers --upgrade\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "699a73ec-b079-4928-9ed2-63583291d0a5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: torch 2.3.0\n",
      "Uninstalling torch-2.3.0:\n",
      "  Would remove:\n",
      "    /home/studio-lab-user/.conda/envs/d2l/bin/convert-caffe2-to-onnx\n",
      "    /home/studio-lab-user/.conda/envs/d2l/bin/convert-onnx-to-caffe2\n",
      "    /home/studio-lab-user/.conda/envs/d2l/bin/torchrun\n",
      "    /home/studio-lab-user/.conda/envs/d2l/lib/python3.9/site-packages/functorch/*\n",
      "    /home/studio-lab-user/.conda/envs/d2l/lib/python3.9/site-packages/torch-2.3.0.dist-info/*\n",
      "    /home/studio-lab-user/.conda/envs/d2l/lib/python3.9/site-packages/torch/*\n",
      "    /home/studio-lab-user/.conda/envs/d2l/lib/python3.9/site-packages/torchgen/*\n",
      "Proceed (Y/n)? ^C\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip uninstall torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "45ea79d2-a455-4b00-a847-28c4ab7e566f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mY\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Y' is not defined"
     ]
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "abdbb128-3a9e-4cf3-b3bc-33f1aa96b48b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /home/studio-lab-user/.conda/envs/d2l/lib/python3.9/site-packages (2.3.0)\n",
      "Requirement already satisfied: filelock in /home/studio-lab-user/.conda/envs/d2l/lib/python3.9/site-packages (from torch) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/studio-lab-user/.conda/envs/d2l/lib/python3.9/site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy in /home/studio-lab-user/.conda/envs/d2l/lib/python3.9/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /home/studio-lab-user/.conda/envs/d2l/lib/python3.9/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/studio-lab-user/.conda/envs/d2l/lib/python3.9/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /home/studio-lab-user/.conda/envs/d2l/lib/python3.9/site-packages (from torch) (2024.5.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/studio-lab-user/.conda/envs/d2l/lib/python3.9/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/studio-lab-user/.conda/envs/d2l/lib/python3.9/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/studio-lab-user/.conda/envs/d2l/lib/python3.9/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/studio-lab-user/.conda/envs/d2l/lib/python3.9/site-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/studio-lab-user/.conda/envs/d2l/lib/python3.9/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/studio-lab-user/.conda/envs/d2l/lib/python3.9/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/studio-lab-user/.conda/envs/d2l/lib/python3.9/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/studio-lab-user/.conda/envs/d2l/lib/python3.9/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/studio-lab-user/.conda/envs/d2l/lib/python3.9/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/studio-lab-user/.conda/envs/d2l/lib/python3.9/site-packages (from torch) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/studio-lab-user/.conda/envs/d2l/lib/python3.9/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.0 in /home/studio-lab-user/.conda/envs/d2l/lib/python3.9/site-packages (from torch) (2.3.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/studio-lab-user/.conda/envs/d2l/lib/python3.9/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.40)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/studio-lab-user/.conda/envs/d2l/lib/python3.9/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/studio-lab-user/.conda/envs/d2l/lib/python3.9/site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "247e940b-599e-47d3-9844-639f199bfc87",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification\n",
    "\n",
    "# Ensure the number of labels matches your classification task\n",
    "num_labels = 8\n",
    "\n",
    "# Initialize the model\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=num_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6022b637-d241-4e3e-9aae-6b4e0daa6804",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TrainingArguments' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m training_args \u001b[38;5;241m=\u001b[39m \u001b[43mTrainingArguments\u001b[49m(\n\u001b[1;32m      2\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./results\u001b[39m\u001b[38;5;124m'\u001b[39m,          \u001b[38;5;66;03m# Output directory\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     num_train_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,              \u001b[38;5;66;03m# Number of training epochs\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     per_device_train_batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m,   \u001b[38;5;66;03m# Batch size for training\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     per_device_eval_batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m,   \u001b[38;5;66;03m# Batch size for evaluation\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     warmup_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m,                \u001b[38;5;66;03m# Number of warmup steps for learning rate scheduler\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m,               \u001b[38;5;66;03m# Strength of weight decay\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     logging_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./logs\u001b[39m\u001b[38;5;124m'\u001b[39m,            \u001b[38;5;66;03m# Directory for storing logs\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     logging_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[1;32m     10\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'TrainingArguments' is not defined"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          # Output directory\n",
    "    num_train_epochs=3,              # Number of training epochs\n",
    "    per_device_train_batch_size=8,   # Batch size for training\n",
    "    per_device_eval_batch_size=16,   # Batch size for evaluation\n",
    "    warmup_steps=500,                # Number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # Strength of weight decay\n",
    "    logging_dir='./logs',            # Directory for storing logs\n",
    "    logging_steps=10,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d70628-881c-4c86-b2ae-b8a5455a1b00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l:Python",
   "language": "python",
   "name": "conda-env-d2l-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
